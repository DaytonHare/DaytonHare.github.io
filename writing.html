// Project: Dayton Hare — Michigan Daily Articles
// File: README.md

# Dayton Hare — Michigan Daily Articles

A small React single-file app (Tailwind) to showcase all articles written by **Dayton Hare** for *The Michigan Daily*.

This repo contains:

- `src/App.jsx` — main React component (default export) that loads `public/articles.json` and displays the articles.
- `scripts/scrape.js` — Node script to scrape Dayton Hare's author pages on The Michigan Daily and create `public/articles.json`.
- `public/articles.json` — generated JSON of articles (created by the script).
- `package.json` — dependencies and scripts.
- `tailwind.config.cjs` and `postcss.config.cjs` — Tailwind setup.

## How it works
1. Run `node scripts/scrape.js` to fetch the author pages and create `public/articles.json`.
2. Run `npm install` then `npm start` to serve the React app (or `npm run build`).

---

// File: package.json

{
  "name": "dayton-hare-articles",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "start": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "scrape": "node scripts/scrape.js"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "vite": "^5.0.0",
    "tailwindcss": "^4.0.0",
    "postcss": "^8.0.0",
    "autoprefixer": "^10.0.0",
    "cheerio": "^1.0.0-rc.12",
    "node-fetch": "^3.3.0"
  }
}

---

// File: tailwind.config.cjs

module.exports = {
  content: ["./index.html", "./src/**/*.{js,jsx}"],
  theme: { extend: {} },
  plugins: []
};

---

// File: postcss.config.cjs

module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {}
  }
};

---

// File: index.html

<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Dayton Hare — Michigan Daily Articles</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

---

// File: src/main.jsx

import React from 'react'
import { createRoot } from 'react-dom/client'
import App from './App'
import './index.css'

createRoot(document.getElementById('root')).render(<App />)

---

// File: src/index.css

@tailwind base;
@tailwind components;
@tailwind utilities;

body { @apply bg-slate-50 text-slate-800; }

---

// File: src/App.jsx

import React, { useEffect, useState } from 'react'

export default function App() {
  const [articles, setArticles] = useState([])
  const [q, setQ] = useState('')
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    async function fetchArticles() {
      try {
        const res = await fetch('/articles.json')
        const data = await res.json()
        // sort newest first (if date exists)
        data.sort((a,b) => (new Date(b.date || 0)) - (new Date(a.date || 0)))
        setArticles(data)
      } catch (e) {
        console.error('Failed to load articles.json', e)
      } finally {
        setLoading(false)
      }
    }
    fetchArticles()
  }, [])

  const filtered = articles.filter(a => {
    if (!q) return true
    const s = q.toLowerCase()
    return (a.title || '').toLowerCase().includes(s) || (a.excerpt || '').toLowerCase().includes(s) || (a.tags || []).join(' ').toLowerCase().includes(s)
  })

  return (
    <div className="min-h-screen p-6 max-w-5xl mx-auto">
      <header className="mb-8">
        <h1 className="text-4xl font-bold">Dayton Hare — Michigan Daily</h1>
        <p className="mt-2 text-slate-600">A curated list of articles written by Dayton Hare for <em>The Michigan Daily</em>.</p>
      </header>

      <div className="mb-6 flex gap-4 items-center">
        <input value={q} onChange={e => setQ(e.target.value)} placeholder="Search titles, excerpts, tags..." className="flex-1 p-3 rounded-lg shadow-sm border" />
        <div className="text-slate-500">{loading ? 'Loading…' : `${filtered.length} article(s)`}</div>
      </div>

      <main>
        {filtered.length === 0 && !loading && (
          <div className="p-6 bg-white rounded-lg shadow-sm text-center text-slate-600">No articles found.</div>
        )}

        <ul className="grid gap-4 sm:grid-cols-2">
          {filtered.map((a) => (
            <li key={a.url} className="bg-white rounded-lg p-4 shadow-sm">
              <a href={a.url} target="_blank" rel="noopener noreferrer" className="text-lg font-semibold hover:underline">{a.title}</a>
              <div className="mt-1 text-sm text-slate-500">{a.date}</div>
              {a.excerpt && <p className="mt-3 text-slate-700">{a.excerpt}</p>}
              {a.tags && a.tags.length > 0 && (
                <div className="mt-3 flex flex-wrap gap-2">
                  {a.tags.map(t => <span key={t} className="text-xs px-2 py-1 border rounded-full">{t}</span>)}
                </div>
              )}
            </li>
          ))}
        </ul>
      </main>

      <footer className="mt-12 text-sm text-slate-500">
        Data source: The Michigan Daily author pages. This site is an independent aggregator.
      </footer>
    </div>
  )
}

---

// File: scripts/scrape.js

/*
 Simple Node scraper to produce `public/articles.json` by scraping the author pages on The Michigan Daily.
 Notes:
 - The Michigan Daily may paginate author pages; this script will iterate pages until no more article nodes are found.
 - This is an example — depending on the site structure you might need to tweak selectors.
*/

import fetch from 'node-fetch'
import cheerio from 'cheerio'
import fs from 'fs'

const BASE = 'https://www.michigandaily.com'
const AUTHOR = '/author/dayton-hare/'

async function fetchPage(url) {
  const r = await fetch(url, { headers: { 'User-Agent': 'Mozilla/5.0 (compatible; DaytonHareScraper/1.0)'}})
  if (!r.ok) throw new Error(`HTTP ${r.status} ${r.statusText}`)
  return await r.text()
}

async function main() {
  let page = 1
  const articles = []
  while (true) {
    const pageUrl = page === 1 ? `${BASE}${AUTHOR}` : `${BASE}${AUTHOR}page/${page}/`
    console.log('Fetching', pageUrl)
    const html = await fetchPage(pageUrl)
    const $ = cheerio.load(html)

    // Adjust selector to match the site markup. Common pattern: article entries under .post or .node
    const nodes = $('.node, article, .post')
    if (!nodes || nodes.length === 0) break

    let found = 0
    nodes.each((i, el) => {
      const titleEl = $(el).find('h2 a, .title a, a').first()
      const title = titleEl.text().trim()
      const url = titleEl.attr('href') ? (titleEl.attr('href').startsWith('http') ? titleEl.attr('href') : `${BASE}${titleEl.attr('href')}`) : null
      const date = $(el).find('time').attr('datetime') || $(el).find('.date').text().trim()
      const excerpt = $(el).find('.teaser, .excerpt, p').first().text().trim()

      if (title && url) {
        articles.push({ title, url, date, excerpt })
        found++
      }
    })

    if (found === 0) break
    page++
  }

  fs.mkdirSync('./public', { recursive: true })
  fs.writeFileSync('./public/articles.json', JSON.stringify(articles, null, 2))
  console.log('Wrote', articles.length, 'articles to public/articles.json')
}

main().catch(e => { console.error(e); process.exit(1) })

---

// File: public/articles.json

[]

---

// End of project files
